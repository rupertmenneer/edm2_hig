{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from hig_data.coco2 import COCOStuffGraphPrecomputedDataset\n",
    "from hig_data.utils import DataLoader\n",
    "import torch\n",
    "# new_coco_val2017_hig.h5\n",
    "# aug_coco_train2017_hig.h5\n",
    "path = '/home/rfsm2/rds/hpc-work/datasets/coco/precomputed_coco_val_paths.json'\n",
    "dataset = COCOStuffGraphPrecomputedDataset(path, swapped=False, )\n",
    "from hig_data.utils import DataLoader\n",
    "dls = DataLoader(dataset, batch_size=8, subsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "graph_batch = next(iter(dls))\n",
    "ckpt_path = '/home/rfsm2/rds/hpc-work/training_runs/edm2_pretrained_med/backup_nov_26/edm2-coco256-m_Nov_26_hr_11training-state-0033554.pt'\n",
    "ckpt = torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.networks_edm2_hignn_control import Precond\n",
    "precond = Precond(64, 4, gnn_metadata = graph_batch.metadata(), model_channels=256, label_dim=768)\n",
    "precond.load_state_dict(ckpt['net'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "\n",
    "run_dir = '/home/rfsm2/rds/hpc-work/training_runs/edm2_pretrained_xs_uncond/pretrained'\n",
    "pattern=r'edm2-img512.*(\\d+).pkl'\n",
    "verbose=True\n",
    "fnames = [entry.name for entry in os.scandir(run_dir) if entry.is_file() and re.fullmatch(pattern, entry.name)]\n",
    "print(fnames)\n",
    "pkl_path = os.path.join(run_dir, max(fnames, key=lambda x: float(re.fullmatch(pattern, x).group(1))))\n",
    "\n",
    "if verbose:\n",
    "    print(f'Loading from {pkl_path} ... ', end='', flush=True)\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    data = pickle.load(f, fix_imports=True, encoding=\"bytes\")\n",
    "\n",
    "pretrained = data.ema\n",
    "\n",
    "# # Extract the model state dict from the .pkl data\n",
    "# model_state_dict = data.ema.state_dict()\n",
    "\n",
    "# # filters out anything not in model_state + mismatched sizes + emb gain parameter (we want 0 cond emb gain at start of training)\n",
    "# model_state_dict = {k: v for k, v in model_state_dict.items() if 'emb_label' not in k}\n",
    "\n",
    "# # Non-strictly load the state dict into the target model\n",
    "# pretrained_uncond = Precond(64, 4, gnn_metadata = dataset[0].metadata(), model_channels=128, label_dim=0)\n",
    "# pretrained_uncond.load_state_dict(model_state_dict, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from training.networks_edm2_hignn_control import Precond\n",
    "graph_batch = next(iter(dls))\n",
    "ckpt_path = '/home/rfsm2/rds/hpc-work/training_runs/edm2_pretrained_med/backup_nov_26/edm2-coco256-m_Nov_26_hr_11training-state-0033554.pt'\n",
    "ckpt = torch.load(ckpt_path)\n",
    "control_net = Precond(64, 4, gnn_metadata = dataset[0].metadata(), model_channels=256, label_dim=768)\n",
    "control_net.load_state_dict(ckpt['net'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_images import edm_sampler\n",
    "\n",
    "\n",
    "sample_shape = (8, 4, 64, 64)\n",
    "noise = torch.randn(sample_shape, device='cuda')\n",
    "sampled = edm_sampler(net=control_net.to(noise.device), noise=noise, graph=graph_batch, num_steps=64,) # samp\n",
    "# sampled = edm_sampler(net=control_net.to(noise.device), gnet=pretrained.to(noise.device), noise=noise, graph=graph_batch, num_steps=64, guidance=1.4) # sample images from noise and graph batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hig_data.visualisation import plot_array_images\n",
    "from training.encoders import StabilityVAEEncoder\n",
    "# graph_batch = next(iter(dls))\n",
    "vae = StabilityVAEEncoder(batch_size=8)\n",
    "# print(graph_batch.image.shape, sampled.shape)\n",
    "ground_truth = vae.decode(vae.encode_latents(graph_batch.image.to('cuda')))\n",
    "sampled_pixels = vae.decode(sampled.to('cuda'))\n",
    "plot_array_images(sampled_pixels.cpu()) \n",
    "plot_array_images(ground_truth.cpu()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_uncond.unet.init_control_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_images import edm_sampler\n",
    "\n",
    "graph_batch = next(iter(dls))\n",
    "sample_shape = (8, 4, 64, 64)\n",
    "noise = torch.randn(sample_shape, device='cuda')\n",
    "# sampled = edm_sampler(net=precond.to(noise.device), gnet=pretrained_uncond.to(noise.device), noise=noise, graph=graph_batch, num_steps=64, guidance=1.1) # sample images from noise and graph batch\n",
    "sampled = edm_sampler(net=pretrained_uncond.to(noise.device), noise=noise, graph=graph_batch, num_steps=64,) # samp\n",
    "# sampled = edm_sampler(net=data.ema.to(noise.device), noise=noise, graph=graph_batch, num_steps=64,) # samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hig_data.visualisation import plot_array_images\n",
    "from training.encoders import StabilityVAEEncoder\n",
    "# graph_batch = next(iter(dls))\n",
    "vae = StabilityVAEEncoder(batch_size=8)\n",
    "# print(graph_batch.image.shape, sampled.shape)\n",
    "# ground_truth = vae.decode(vae.encode_latents(graph_batch.image.to('cuda')))\n",
    "sampled_pixels = vae.decode(sampled.to('cuda'))\n",
    "plot_array_images(sampled_pixels.cpu()) \n",
    "# plot_array_images(ground_truth.cpu()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_images import edm_sampler\n",
    "\n",
    "graph_batch = next(iter(dls))\n",
    "sample_shape = (8, 4, 64, 64)\n",
    "noise = torch.randn(sample_shape, device='cuda')\n",
    "# sampled = edm_sampler(net=precond.to(noise.device), gnet=pretrained_uncond.to(noise.device), noise=noise, graph=graph_batch, num_steps=64, guidance=1.1) # sample images from noise and graph batch\n",
    "# sampled = edm_sampler(net=pretrained_uncond.to(noise.device), noise=noise, graph=None, num_steps=64,) # samp\n",
    "sampled = edm_sampler(net=pretrained_uncond.to(noise.device), noise=noise, graph=graph_batch, num_steps=64,) # samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hig_data.visualisation import plot_array_images\n",
    "from training.encoders import StabilityVAEEncoder\n",
    "# graph_batch = next(iter(dls))\n",
    "vae = StabilityVAEEncoder(batch_size=8)\n",
    "# print(graph_batch.image.shape, sampled.shape)\n",
    "# ground_truth = vae.decode(vae.encode_latents(graph_batch.image.to('cuda')))\n",
    "sampled_pixels = vae.decode(sampled.to('cuda'))\n",
    "plot_array_images(sampled_pixels.cpu()) \n",
    "# plot_array_images(ground_truth.cpu()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "optimizer_kwargs = dict(betas=(0.9, 0.99), lr=1e-2)\n",
    "net = pretrained_uncond\n",
    "new_params = [param for name, param in net.named_parameters() if 'hignn' in name]\n",
    "pretrained_params = [param for name, param in net.named_parameters() if 'hignn' not in name]\n",
    "\n",
    "optimizer = Adam(params=[{\"params\": pretrained_params, \"lr\": 1e-5}, {\"params\": new_params,}], **optimizer_kwargs)\n",
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
